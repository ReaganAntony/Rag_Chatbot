ğŸ“ RAG-Agent: Multi-Document Chatbot with Local EmbeddingsA high-performance Retrieval-Augmented Generation (RAG) chatbot that allows users to upload documents and have context-aware conversations. This project combines the privacy/speed of local embeddings (LangChain) with the reasoning power of Google Gemini.ğŸš€ 
FeaturesLocal Processing: PDF text extraction and document chunking are handled locally.Hybrid Embedding Pipeline: Uses LangChain with local embedding models for fast, cost-effective vector generation.Vector Persistence: Powered by ChromaDB for efficient similarity search and long-term storage of document vectors.Strict Agentic Reasoning: Uses a "Strict Prompt" via the Gemini API to ensure the agent only answers based on the provided context (reducing hallucinations).Session Management: Intelligent tracking of uploaded document IDs to prevent duplicate processing.
ğŸ—ï¸ Technical ArchitectureIngestion Phase: * Extraction: Text is pulled from user-uploaded PDFs/Docs.Chunking: Text is split into overlapping segments to preserve context.Vectorization: Local embeddings are generated (via LangChain).Storage: Vectors are indexed in a local ChromaDB instance.Retrieval Phase: * User query is converted into a vector.Top-$k$ most relevant chunks are retrieved from ChromaDB.Generation Phase: * Retrieved chunks + user query + Strict System Prompt are sent to the Gemini API.Agent generates a response anchored strictly to the data.ğŸ› ï¸ Tech StackLLM: Google Gemini (Generative AI)Framework: LangChainVector Database: ChromaDBEmbeddings: Local Embeddings (HuggingFace/Sentence-Transformers)Language: Python 3.10+Backend: FastAPI / Uvicorn (if applicable)
